{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_PATH = \"../data/bengali_AI_handwritten_grapheme_classification\"\n",
    "\n",
    "DATASET_PATH_1 = \"../data/bengali_centered/dataset_1\"\n",
    "DATASET_PATH_2 = \"../data/bengali_centered/dataset_2\"\n",
    "DATASET_PATH_3 = \"../data/bengali_centered/dataset_3\"\n",
    "DATASET_PATH_4 = \"../data/bengali_centered/dataset_4\"\n",
    "\n",
    "IMG_HEIGHT = 137\n",
    "IMG_WIDTH = 236\n",
    "\n",
    "ROOT_CLASSES_NUM = 168\n",
    "CONSONANT_CLASSES_NUM = 7\n",
    "VOWEL_CLASSES_NUM = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"{}/train.csv\".format(DATA_DIR_PATH))\n",
    "test_df = pd.read_csv(\"{}/test.csv\".format(DATA_DIR_PATH))\n",
    "class_map_df = pd.read_csv(\"{}/class_map.csv\".format(DATA_DIR_PATH))\n",
    "sample_submission_df = pd.read_csv(\"{}/sample_submission.csv\".format(DATA_DIR_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet_data(dir_path: str, num_file: int, data_type: str) -> list:\n",
    "    df_list = list()\n",
    "    data_type = data_type.lower()\n",
    "    \n",
    "    for i in range(num_file):\n",
    "        df = pd.read_parquet(\"{}/{}_image_data_{}.parquet\".format(dir_path, data_type, i))\n",
    "        df.set_index('image_id', inplace=True)\n",
    "        df_list.append(df)\n",
    "        \n",
    "        print(\"Reading {} th parquet file is done\".format(i))\n",
    "    \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train dataset\n",
    "train_df_list = read_parquet_data(dir_path=DATA_DIR_PATH, num_file=4, data_type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test dataset\n",
    "test_df_list = read_parquet_data(dir_path=DATA_DIR_PATH, num_file=4, data_type=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_img(img_data):\n",
    "    if isinstance(img_data, pd.Series):\n",
    "        img_data = img_data.to_numpy()\n",
    "    \n",
    "    return img_data.reshape(IMG_HEIGHT, IMG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "    plt.xticks(range(0, IMG_WIDTH, 10))\n",
    "    plt.yticks(range(0, IMG_HEIGHT, 5))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_dict(class_map_df: pd.DataFrame) -> dict:\n",
    "    class_dict = dict()\n",
    "\n",
    "    for component_type in set(class_map_df['component_type']):\n",
    "        output_df = class_map_df[class_map_df['component_type'] == component_type]\n",
    "        output_df.drop('component_type', axis=1, inplace=True)\n",
    "        output_df.index = output_df['label']\n",
    "\n",
    "        class_dict[component_type] = output_df\n",
    "\n",
    "    return class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_image(img, threshhold=10):\n",
    "    img = img.astype(np.int64)\n",
    "\n",
    "    mask = np.ones_like(img, dtype=np.int64) * 255\n",
    "    img = abs(img - mask)\n",
    "    \n",
    "    img[img < threshhold] = 0\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_edge(images) :\n",
    "    # 위 2 픽셀\n",
    "    images[:, :2] = 0\n",
    "    # 아래 2 픽셀\n",
    "    images[:, IMG_HEIGHT-2:] = 0\n",
    "    # 왼쪽 2 픽셀\n",
    "    images[:, :, :2] = 0\n",
    "    # 오른쪽 2 픽셀\n",
    "    images[:, :, IMG_WIDTH-2:] = 0\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_range(data):\n",
    "    cut_image = np.array([])\n",
    "    max_x = 0\n",
    "    max_y = 0\n",
    "    len_d = 0\n",
    "    \n",
    "    for i in data:\n",
    "        x1 = 0\n",
    "        y1 = 0\n",
    "        x2 = 0\n",
    "        y2 = 0\n",
    "        for j in range(0, IMG_HEIGHT):\n",
    "            for k in range(0, IMG_WIDTH):\n",
    "                # x1 init\n",
    "                if i[j][k] > 0 and x1 == 0:\n",
    "                    x1 = k\n",
    "                # y1 init\n",
    "                if i[j][k] > 0 and y1 == 0:\n",
    "                    y1 = j\n",
    "\n",
    "                # x1 update\n",
    "                if i[j][k] > 0 and k < x1:\n",
    "                    x1 = k\n",
    "                # y1 update\n",
    "                if i[j][k] > 0 and j < y1:\n",
    "                    y1 = j\n",
    "                # x2 update\n",
    "                if i[j][k] > 0 and x1 != 0 and k > x2:\n",
    "                    x2 = k\n",
    "                # y2 update\n",
    "                if i[j][k] > 0 and y1 != 0 and j > y2:\n",
    "                    y2 = j\n",
    "\n",
    "        image_set = [x1, x2, y1, y2]\n",
    "\n",
    "        if x2-x1+1 > max_x:\n",
    "            max_x = x2-x1+1\n",
    "        if y2-y1+1 > max_y:\n",
    "            max_y = y2-y1+1\n",
    "\n",
    "        cut_image = np.append(cut_image, image_set, axis=0)\n",
    "        len_d += 1\n",
    "\n",
    "    cut_image = cut_image.reshape(-1, 4)\n",
    "    return cut_image # max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(data, cut_image):\n",
    "    padding_img = np.array([])\n",
    "    center_size_x = IMG_WIDTH // 2\n",
    "    center_size_y = IMG_HEIGHT // 2\n",
    "\n",
    "    for i in range(len(cut_image)):\n",
    "        init = np.zeros((137, 236))\n",
    "\n",
    "        x_size = int((cut_image[i][1] - cut_image[i][0]) / 2)\n",
    "        y_size = int((cut_image[i][3] - cut_image[i][2]) / 2)\n",
    "        data_center_X = int((cut_image[i][0] + cut_image[i][1]) / 2)\n",
    "        data_center_Y = int((cut_image[i][2] + cut_image[i][3]) / 2)\n",
    "\n",
    "        init[center_size_y-y_size:center_size_y+y_size+1, center_size_x-x_size:center_size_x+x_size+1] \\\n",
    "        = data[i][data_center_Y-y_size:data_center_Y+y_size+1, data_center_X-x_size:data_center_X+x_size+1]\n",
    "\n",
    "        padding_img = np.append(padding_img, init)\n",
    "\n",
    "    padding_img = padding_img.reshape(-1, 137, 236)\n",
    "    return padding_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save centered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_centered_image(img_df, dataset_path: str):\n",
    "    Path(dataset_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for image_name, row in tqdm.tqdm(img_df.iterrows(), total=img_df.shape[0]):\n",
    "        img = inverse_image(row, threshhold=50)\n",
    "        img = img.to_numpy()\n",
    "        img = img.reshape(-1, IMG_HEIGHT, IMG_WIDTH)\n",
    "        \n",
    "        cropped_img = remove_edge(img)\n",
    "        cut_image = num_range(cropped_img)\n",
    "        pad_img = pad_image(img, cut_image)\n",
    "        \n",
    "        plt.imsave(os.path.join(dataset_path, \"{}.jpg\".format(image_name)), pad_img[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_centered_image(row):\n",
    "    img = inverse_image(row, threshhold=50)\n",
    "    img = img.to_numpy()\n",
    "    img = img.reshape(-1, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "    cropped_img = remove_edge(img)\n",
    "    print(\"removed edge check : \", cropped_img[:,0])\n",
    "    cut_image = num_range(cropped_img)\n",
    "    print(\"cropped image position: \", cut_image)\n",
    "    pad_img = pad_image(img, cut_image)\n",
    "\n",
    "    return pad_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "crop-crop-pad 한 결과 중 이상한 것\n",
    "50320 - 원본 확인 필요\n",
    "51120 - 원본 확인 필요\n",
    "\n",
    "51694 - 오른쪽 점때문에 센터링 안됨\n",
    "52225 - 위에 선\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
